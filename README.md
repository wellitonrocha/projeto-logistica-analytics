# ğŸ“¦ projeto-logistica-analytics

Projeto de **Analytics LogÃ­stico** desenvolvido com foco em **SQL avanÃ§ado**, engenharia de dados e anÃ¡lise de performance operacional e financeira, utilizando uma arquitetura completa de **Data Warehouse** e visualizaÃ§Ã£o no **Power BI**.

---

## ğŸ“Œ 1. VisÃ£o Geral do Projeto

OperaÃ§Ãµes logÃ­sticas geram grandes volumes de dados relacionados a **pedidos, custos de frota, prazos de entrega e ocorrÃªncias operacionais**. Sem um modelo de dados bem estruturado e regras claras de negÃ³cio, esses dados nÃ£o se convertem em informaÃ§Ã£o confiÃ¡vel para tomada de decisÃ£o.

O **projeto-logistica-analytics** foi desenvolvido para simular um **cenÃ¡rio corporativo real**, no qual dados operacionais sÃ£o tratados, organizados e disponibilizados para anÃ¡lises estratÃ©gicas.  

O projeto tem como **pilar central o uso avanÃ§ado de SQL**, aplicado de forma consistente em todo o pipeline de dados. Ao mesmo tempo, apresenta uma visÃ£o **end-to-end**, cobrindo engenharia de dados, modelagem dimensional, qualidade, governanÃ§a e visualizaÃ§Ã£o analÃ­tica no Power BI.

ğŸ¯ **Objetivo principal:** transformar dados operacionais brutos em **informaÃ§Ã£o confiÃ¡vel, analÃ­tica e acionÃ¡vel**.

---

## ğŸ¯ 2. Objetivos do Projeto

### ğŸ”§ Objetivos TÃ©cnicos
- Demonstrar domÃ­nio avanÃ§ado de **SQL Server**
- Construir um pipeline de dados organizado em mÃºltiplas camadas
- Aplicar boas prÃ¡ticas de modelagem relacional e dimensional
- Garantir integridade, consistÃªncia e rastreabilidade dos dados

### ğŸ“Š Objetivos AnalÃ­ticos
- Criar mÃ©tricas logÃ­sticas padronizadas (OTIF, On Time, In Full)
- Analisar custos, receita e rentabilidade da operaÃ§Ã£o
- Avaliar desempenho por filial, tipo de veÃ­culo e regiÃ£o
- Permitir anÃ¡lises temporais e geogrÃ¡ficas confiÃ¡veis

### ğŸ’¼ Objetivos de NegÃ³cio
- Apoiar decisÃµes sobre eficiÃªncia operacional
- Identificar gargalos logÃ­sticos
- Avaliar nÃ­vel de serviÃ§o e impacto financeiro das operaÃ§Ãµes

---

## ğŸ—ï¸ 3. Arquitetura da SoluÃ§Ã£o

O projeto segue uma arquitetura clÃ¡ssica de **Data Warehouse corporativo**, organizada em camadas bem definidas para garantir clareza, governanÃ§a e escalabilidade.

### ğŸ”„ Fluxo de Dados
- Fonte de dados operacional  
- **Staging (STG)** â€” dados brutos  
- **ODS** â€” dados tratados e padronizados  
- **Data Warehouse (DW)** â€” modelo analÃ­tico  
- **Power BI** â€” camada de consumo e visualizaÃ§Ã£o  

### ğŸ—‚ï¸ Schemas Utilizados
- **stg**: ingestÃ£o dos dados brutos
- **ods**: dados tratados, tipados e validados
- **dw**: fatos e dimensÃµes para anÃ¡lise

Boas prÃ¡ticas adotadas incluem separaÃ§Ã£o de responsabilidades por camada, integridade referencial, padronizaÃ§Ã£o de tipos e uso de views para consumo analÃ­tico.

---

## ğŸ§± 4. Modelagem de Dados

Foi adotada uma **modelagem hÃ­brida**:
- Relacional nas camadas STG e ODS
- Dimensional (modelo estrela) no Data Warehouse

### ğŸ“Œ Tabelas Fato
- **Fato_Pedido**: mÃ©tricas operacionais e financeiras dos pedidos
- **Fato_Custo**: custos recorrentes da frota ao longo do tempo

### ğŸ“Œ DimensÃµes
- Tempo
- VeÃ­culo
- Filial
- OcorrÃªncia
- Localidade (Cidade, UF, RegiÃ£o)

Essa abordagem respeita a granularidade real dos dados e evita distorÃ§Ãµes analÃ­ticas.

### ğŸ“· Diagrama da Modelagem
> *Inserir imagem da modelagem dimensional*

---

## ğŸ§  5. SQL â€” Pilar Central do Projeto

O **SQL Ã© o nÃºcleo tÃ©cnico** deste projeto e foi utilizado em todas as etapas da soluÃ§Ã£o.

Principais aplicaÃ§Ãµes:
- CriaÃ§Ã£o de schemas, tabelas e constraints
- Desenvolvimento de views analÃ­ticas
- ImplementaÃ§Ã£o de regras de negÃ³cio no banco
- TransformaÃ§Ãµes complexas e padronizaÃ§Ã£o de dados

Foram utilizados conceitos como:
- CTEs para organizaÃ§Ã£o e legibilidade
- Joins complexos entre mÃºltiplas entidades
- Tratamento de dados inconsistentes
- Escrita de queries orientadas Ã  performance e manutenÃ§Ã£o

ğŸ“Œ O foco foi construir SQL **legÃ­vel, escalÃ¡vel e alinhado a boas prÃ¡ticas corporativas**.

---

## ğŸ§¹ 6. Qualidade e Tratamento de Dados

A qualidade dos dados foi tratada como requisito essencial.

Principais cuidados adotados:
- Limpeza de dados invÃ¡lidos
- PadronizaÃ§Ã£o de formatos e tipos
- CorreÃ§Ã£o de inconsistÃªncias oriundas da fonte
- Controle de duplicidade
- Garantia de integridade entre fatos e dimensÃµes

Essas prÃ¡ticas asseguram que as anÃ¡lises reflitam corretamente a realidade operacional.

---

## ğŸ“Š 7. Power BI â€” Camada AnalÃ­tica e Visual

O Power BI foi utilizado como camada final de consumo, conectado diretamente Ã s views do Data Warehouse.

### Destaques da SoluÃ§Ã£o
- Modelo semÃ¢ntico alinhado Ã  modelagem dimensional
- Relacionamentos claros e bem definidos
- MÃ©tricas em DAX baseadas em regras de negÃ³cio sÃ³lidas
- Dashboards orientados Ã  tomada de decisÃ£o

### Principais Indicadores
- Receita Bruta
- Custo Total
- Resultado e Margem Operacional
- OTIF, On Time e In Full
- Order Cycle Time
- Volume de pedidos e ocorrÃªncias

### ğŸ“· Prints dos Dashboards
> *Inserir imagens das abas do Power BI*

---

## ğŸ› ï¸ 8. Tecnologias Utilizadas

- SQL Server
- SQL (DDL, DML, CTEs, Views)
- Power BI
- GitHub

---

## ğŸ“š 9. Principais Aprendizados

- AplicaÃ§Ã£o prÃ¡tica de SQL em um pipeline completo
- ImportÃ¢ncia da modelagem correta para anÃ¡lises confiÃ¡veis
- SeparaÃ§Ã£o clara entre dados operacionais e analÃ­ticos
- Impacto direto da qualidade dos dados no BI
- ConstruÃ§Ã£o de mÃ©tricas logÃ­sticas auditÃ¡veis

---

## ğŸš€ 10. PrÃ³ximos Passos e EvoluÃ§Ãµes Futuras

- AutomatizaÃ§Ã£o do pipeline de dados
- ImplementaÃ§Ã£o de cargas incrementais
- Monitoramento de qualidade de dados
- IntegraÃ§Ã£o com novas fontes
- EvoluÃ§Ã£o para anÃ¡lises preditivas

---

ğŸ‘¤ **Autor:** Welliton da Rocha  
Projeto desenvolvido com foco em **Engenharia de Dados, SQL AvanÃ§ado e Analytics aplicado ao negÃ³cio**.
